# Benchmarking Large Language Models in Evidence-Based Medicine

Evidence-based medicine (EBM) represents a paradigm of providing patient care grounded in the most current and rigorously evaluated research. Recent advances in large language models (LLMs) offer a potential solution to transform EBM by automating labor-intensive tasks and thereby improving the efficiency of clinical decision-making.
This study explores integrating LLMs into the key stages in EBM, evaluating their ability across evidence retrieval (PICO extraction, biomedical question answering), synthesis (summarizing randomized controlled trials), and dissemination (medical text simplification). We conducted a comparative analysis of seven LLMs, including both proprietary and open-source models, as well as those fine-tuned on medical corpora.

## Getting Started

The instructions below will guide you through the process of setting up and running the RGAN-LS model on your local machine.

### Prerequisites

You will need Python 3.6+ and the following packages:

- Pandas  - 1.1.3
- Numpy - 1.21.2
- TensorFlow - 1.14.0
- Keras - 2.2.5
- Matplotlib - 3.3.3
- Scikit-learn - 0.23.2

### Configuration

You can modify the hyperparameters for training in the `params` dictionary within the main function. Expand `params_list` to include multiple hyperparameter configurations for grid search.

### Training

The training process involves:

1. Reading and normalizing the dataset.
2. Defining time steps for prediction.
3. Reshaping the data into sequences suitable for RNN input.
4. Training the RGAN-LS model with specified hyperparameters.

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* https://github.com/jsyoon0823/TimeGAN
* https://github.com/olofmogren/c-rnn-gan